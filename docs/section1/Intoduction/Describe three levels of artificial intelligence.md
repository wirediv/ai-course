# Understanding AI: Types and Capabilities

Artificial intelligence (AI) can be described across **different levels or types**, reflecting its capabilities and how it processes information. The sources provide two main frameworks for categorising AI: **capability-based levels** and **functionality-based levels**.

### Capability-Based Levels

This framework categorises AI into three main types based on their intelligence levels relative to human capabilities:

1. **Artificial Narrow Intelligence (ANI) / Weak AI**
    
    - **Description**: ANI, also known as weak AI, is the most common type of AI found today. These systems are **specialized in a single task or domain** and cannot perform tasks outside their pre-programmed scope. Their "intelligence" is demonstrated only within these specific areas. Even emerging generative AI applications, despite their advancements, are considered weak AI because they cannot be repurposed for other domains.
    - **Capabilities**: ANI systems are limited to computing specifications, algorithms, and the specific tasks they are designed for. They may have limited memories and rely only on real-time data to make decisions. They require substantial training with specific datasets to work reliably with unfamiliar data within their domain.
    - **Examples**: Facial recognition software, AI summarizers, Google Search, predictive analytics, virtual assistants like Amazon Alexa, Apple Siri, or Google Assistant, and self-driving automobiles. IBM's Deep Blue, which defeated world chess champion Garry Kasparov in 1997, is also an example of a reactive machine, a form of narrow AI.
2. **Artificial General Intelligence (AGI) / Strong AI**
    
    - **Description**: AGI, also referred to as strong AI or general AI, is a **hypothetical stage** in AI development. The aim of AGI research is to create software with human-like intelligence and the **ability to self-teach**, enabling it to perform tasks it was not specifically trained or developed for. It represents the fundamental goal of AI development: the artificial replication of human intelligence in a machine or software. AGI can solve complex problems in various domains, like a human being, without manual intervention.
    - **Key Distinctions**: Unlike current AI that requires substantial training for related tasks within the same domain (e.g., fine-tuning an LLM with medical datasets to become a medical chatbot), an AGI system could learn and handle unfamiliar tasks without additional training. Strong AI, a concept often conflated with AGI, specifically refers to an AI system demonstrating consciousness and is considered a conscious mind, rather than merely a tool. Consciousness is usually implied as either a prerequisite or consequence of general intelligence.
    - **Challenges in Research**: Achieving AGI is a **distant goal** and poses significant challenges. These include limited computer power, the intractability of problems leading to "combinatorial explosion" (where finding optimal solutions requires extraordinary computer time), and Moravec's paradox (where AI excels at "intelligent" tasks but struggles with "unintelligent" tasks like perception). It also requires overcoming the vastness of commonsense knowledge and representing commonsense reasoning, which is difficult to formalize with precise definitions. Furthermore, current neural networks struggle to replicate authentic human creativity and emotional thinking. AGI systems would also need to physically interact with the external environment and perceive the world as humans do, requiring advancements beyond existing computer technologies.
    - **Theoretical Approaches**: AI experts have proposed several methods for AGI research:
        - **Symbolic approach**: Assumes AGI can be developed by representing human thoughts with expanding logic networks, using if-else logic to interpret ideas at a higher thinking level. However, it struggles with lower-level cognitive abilities like perception.
        - **Connectionist (or emergentist) approach**: Focuses on replicating the human brain's structure with neural-network architecture, hoping to achieve human-like and low-level cognitive capabilities by mimicking how brain neurons alter transmission paths based on external stimuli. Large language models (LLMs) are an example of AI using this method.
        - **Universalists**: While not detailed in the provided sources, this suggests a broader, more integrated approach (implied by).
    - **Technological Drivers**: Deep learning, generative AI, natural language processing (NLP), computer vision, and robotics are considered emerging technologies driving AGI research.
    - **Current Status**: AGI remains a theoretical concept and research goal. No known AI systems currently approach this level of sophistication. However, some researchers have argued that advanced LLMs like GPT-4 could reasonably be viewed as an early, incomplete version of an AGI system, given their ability to solve novel and difficult tasks across various domains.
3. **Artificial Superintelligence (ASI)**
    
    - **Description**: ASI is a **theoretical AI system** whose capabilities vastly exceed those of human beings. It surpasses human intelligence in all aspects, including creativity, problem-solving, and emotional intelligence.
    - **Current Status**: ASI is still largely theoretical and a topic of debate and speculation. While true general superintelligence has not been achieved, there are narrow AI models that demonstrate what could be fairly called superintelligence in their specific tasks, as they exceed human performance.
    - **Examples of "Narrow Superintelligence"**: AlphaFold (predicts protein structures better than humans), IBM Deep Blue (defeated world chess champion Garry Kasparov in 1997), IBM Watson (defeated _Jeopardy!_ champions in 2013), and AlphaGo (considered the world's greatest Go player). However, these models have not achieved artificial "general" intelligence as they cannot autonomously learn new tasks or expand their problem-solving capabilities beyond their narrowly defined scope.

### Functionality-Based Levels

This framework categorises AI based on how machines process information and react to stimuli, reflecting stages of AI development:

1. **Reactive Machines**
    
    - **Description**: This is a limited form of AI that **only reacts to different kinds of stimuli based on pre-programmed rules**. It does not use memory and, therefore, cannot learn with new data.
    - **Examples**: IBM's Deep Blue, which beat chess champion Garry Kasparov in 1997, is an example of a reactive machine. Spam filters are also mentioned as an example.
2. **Limited Memory**
    
    - **Description**: Most modern AI systems fall into this category. They can **use memory to improve over time by being trained with new data**, typically through an artificial neural network or other training model. This capability allows them to use past data for a short period to inform decisions.
    - **Connection to Modern AI**: Deep learning, a subset of machine learning, is considered limited memory AI. This type of AI learns and improves through exposure to vast amounts of data, identifying patterns and relationships that humans may miss.
    - **Examples**: Self-driving cars (which consider recent past observations to navigate) and chatbots are examples of limited memory AI. Recommendation engines also fit this category.
3. **Theory of Mind**
    
    - **Description**: Theory of mind AI describes AI that **does not currently exist**, but research is ongoing into its possibilities. It would be able to **emulate the human mind's decision-making capabilities**, including recognising and remembering emotions and reacting in social situations as a human would.
4. **Self-Aware**
    
    - **Description**: A step above theory of mind AI, self-aware AI describes a **mythical machine** that is aware of its own existence and has the intellectual and emotional capabilities of a human. Like theory of mind AI, **self-aware AI does not currently exist** and remains purely hypothetical.

In summary, while most existing AI is "narrow" and operates at the reactive or limited memory levels, Artificial General Intelligence, Artificial Superintelligence, Theory of Mind AI, and Self-Aware AI remain theoretical concepts and are subjects of ongoing research and speculation.